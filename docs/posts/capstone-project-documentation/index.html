<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <style>
        :root {
            --accent-color: #FF4D4D;
        }
    </style>

    
    
    
    
    
    

    
    <title>Capstone Project Documentation</title>
    <meta name="description" content="Documentation of the project and results">
    <meta name="keywords" content='blog, gokarna, hugo, bike, model, prediction, machine learning'>

    <meta property="og:url" content="https://andersoncastillol.github.io/capstone-project/posts/capstone-project-documentation/">
    <meta property="og:type" content="website">
    <meta property="og:title" content="Capstone Project Documentation">
    <meta property="og:description" content="Documentation of the project and results">
    <meta property="og:image" content="https://andersoncastillol.github.io/capstone-project">
    <meta property="og:image:secure_url" content="https://andersoncastillol.github.io/capstone-project">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Capstone Project Documentation">
    <meta name="twitter:description" content="Documentation of the project and results">
    <meta property="twitter:domain" content="https://andersoncastillol.github.io/capstone-project/posts/capstone-project-documentation/">
    <meta property="twitter:url" content="https://andersoncastillol.github.io/capstone-project/posts/capstone-project-documentation/">
    <meta name="twitter:image" content="https://andersoncastillol.github.io/capstone-project">

    
    <link rel="canonical" href="https://andersoncastillol.github.io/capstone-project/posts/capstone-project-documentation/" />

    
    <link rel="stylesheet" type="text/css" href="/capstone-project/css/normalize.min.css" media="print">

    
    <link rel="stylesheet" type="text/css" href="/capstone-project/css/main.min.css">

    
    <link id="dark-theme" rel="stylesheet" href="/capstone-project/css/dark.min.css">

    
    <script src="/capstone-project/js/bundle.min.edd985581bf860dfb4507e5885197f1680160c7fe19f23b31e183126d99dd596.js" integrity="sha256-7dmFWBv4YN&#43;0UH5YhRl/FoAWDH/hnyOzHhgxJtmd1ZY="></script>

    
    
</head>
<body>
        <script type="text/javascript">
            
            setThemeByUserPref();
        </script><header class="header">
    <nav class="header-nav">

        

        <div class="nav-title">
            <a class="nav-brand" href="https://andersoncastillol.github.io/capstone-project">Bike Availability Prediction Project</a>
        </div>

        <div class="nav-links">
            
            <div class="nav-link">
                <a href="https://andersoncastillol.github.io/capstone-project/"><span data-feather='home'></span> Home </a>
            </div>
            
            <div class="nav-link">
                <a href="https://andersoncastillol.github.io/capstone-project/posts/"><span data-feather='book'></span> Documentation </a>
            </div>
            
            <div class="nav-link">
                <a href="https://github.com/AndersonCastilloL/capstone-project"><span data-feather='github'></span>  </a>
            </div>
            

            <span class="nav-icons-divider"></span>
            <div class="nav-link dark-theme-toggle">
                <span id="dark-theme-toggle-screen-reader-target" class="sr-only"></span>
                <a>
                    <span id="theme-toggle-icon" data-feather="moon"></span>
                </a>
            </div>

            <div class="nav-link" id="hamburger-menu-toggle">
                <span id="hamburger-menu-toggle-screen-reader-target" class="sr-only">menu</span>
                <a>
                    <span data-feather="menu"></span>
                </a>
            </div>

            
            <ul class="nav-hamburger-list visibility-hidden">
                
                <li class="nav-item">
                    <a href="https://andersoncastillol.github.io/capstone-project/"><span data-feather='home'></span> Home </a>
                </li>
                
                <li class="nav-item">
                    <a href="https://andersoncastillol.github.io/capstone-project/posts/"><span data-feather='book'></span> Documentation </a>
                </li>
                
                <li class="nav-item">
                    <a href="https://github.com/AndersonCastilloL/capstone-project"><span data-feather='github'></span>  </a>
                </li>
                
                <li class="nav-item dark-theme-toggle">
                    <span id="dark-theme-toggle-screen-reader-target" class="sr-only">theme</span>
                    <a>
                        <span id="theme-toggle-icon" data-feather="moon"></span>
                    </a>
                </li>
            </ul>

        </div>
    </nav>
</header>
<main id="content">
    <div class="post container">
    <div class="post-header-section">
        <h1>Capstone Project Documentation</h1>
        <small role="doc-subtitle">Documentation of the project and results</small>
        <p class="post-date">
            June 26, 2023
        </p>

        <ul class="post-tags">
        
            <li class="post-tag"><a href="https://andersoncastillol.github.io/capstone-project/tags/bike">bike</a></li>
        
            <li class="post-tag"><a href="https://andersoncastillol.github.io/capstone-project/tags/model">model</a></li>
        
            <li class="post-tag"><a href="https://andersoncastillol.github.io/capstone-project/tags/prediction">prediction</a></li>
        
            <li class="post-tag"><a href="https://andersoncastillol.github.io/capstone-project/tags/machine-learning">machine learning</a></li>
        
        </ul>
    </div>

    <div class="post-content">
        <p>
            <h2 id="whats-bicing-">What&rsquo;s Bicing ?</h2>
<p>The new Bicing service includes more territorial coverage, an increase in the number of bicycles, mixed stations for conventional and electric bicycles, new and improved types of stations and bicycles (safety, anchorage, comfort), extended schedules and much more!</p>
<h2 id="goal">Goal</h2>
<p>There are two main objective in this project:</p>
<ul>
<li>
<p>Predict the number of free docks given the historical data (Docks Availability Percent).</p>
</li>
<li>
<p>Explore new places where stations are needed.</p>
</li>
<li>
<p>Explore how different events affect availability.</p>
</li>
</ul>
<h2 id="get-the-data">Get the Data</h2>
<p>According with the project we have the next sources:</p>
<ul>
<li>The bicing stations status</li>
<li>The bicing stations information</li>
<li>The weather of the city of Barcelona</li>
</ul>
<p>The Bicing stations status and information of the city of Barcelona were downloaded from <a href="https://opendata-ajuntament.barcelona.cat">Open Data BCN</a> and the weather information to join with bicing stations were downloaded from <a href="https://www.meteo.cat">Meteo Cat</a>.</p>
<h3 id="a-download-the-data">a. Download the Data</h3>
<p>The following script was used to download the data from <a href="https://opendata-ajuntament.barcelona.cat">Open Data BCN</a> by year and month:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>import os
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>i2m <span style="color:#f92672">=</span> list<span style="color:#f92672">(</span>zip<span style="color:#f92672">(</span>range<span style="color:#f92672">(</span>1,13<span style="color:#f92672">)</span>, <span style="color:#f92672">[</span><span style="color:#e6db74">&#39;Gener&#39;</span>,<span style="color:#e6db74">&#39;Febrer&#39;</span>,<span style="color:#e6db74">&#39;Marc&#39;</span>,<span style="color:#e6db74">&#39;Abril&#39;</span>,<span style="color:#e6db74">&#39;Maig&#39;</span>,<span style="color:#e6db74">&#39;Juny&#39;</span>,<span style="color:#e6db74">&#39;Juliol&#39;</span>,<span style="color:#e6db74">&#39;Agost&#39;</span>,<span style="color:#e6db74">&#39;Setembre&#39;</span>,<span style="color:#e6db74">&#39;Octubre&#39;</span>,<span style="color:#e6db74">&#39;Novembre&#39;</span>,<span style="color:#e6db74">&#39;Desembre&#39;</span><span style="color:#f92672">]))</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> year in <span style="color:#f92672">[</span>2022, 2021, 2020, 2019<span style="color:#f92672">]</span>:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> month, month_name in i2m:        
</span></span><span style="display:flex;"><span>        os.system<span style="color:#f92672">(</span>f<span style="color:#e6db74">&#34;wget &#39;https://opendata-ajuntament.barcelona.cat/resources/bcn/BicingBCN/{year}_{month:02d}_{month_name}_BicingNou_ESTACIONS.7z&#39;&#34;</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        os.system<span style="color:#f92672">(</span>f<span style="color:#e6db74">&#34;7z x &#39;{year}_{month:02d}_{month_name}_BicingNou_ESTACIONS.7z&#39;&#34;</span><span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        os.system<span style="color:#f92672">(</span>f<span style="color:#e6db74">&#34;rm &#39;{year}_{month:02d}_{month_name}_BicingNou_ESTACIONS.7z&#39;&#34;</span><span style="color:#f92672">)</span>
</span></span></code></pre></div><p>The following script was used to download the data from <a href="https://www.meteo.cat">Meteo Cat</a> and integrate it into the station availability patterns</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># CODE TO RETRIEVE DATA FROM THE WEATHER API AND STORE IT IN A CSV FILE</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># FROM 2019/01/01 TO 2023/03/31</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> requests
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> time
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> datetime <span style="color:#66d9ef">as</span> dt
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> csv 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>key <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;enJH8FUX2z5Ar7NSCJvYI8pAIuDW0XDV9nbSkEMj&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>start_date <span style="color:#f92672">=</span> dt<span style="color:#f92672">.</span>date(<span style="color:#ae81ff">2019</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>end_date <span style="color:#f92672">=</span> dt<span style="color:#f92672">.</span>date(<span style="color:#ae81ff">2023</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">31</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">assert</span> start_date <span style="color:#f92672">&lt;</span> end_date, <span style="color:#e6db74">&#39;Start date must be before end date&#39;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>delta <span style="color:#f92672">=</span> dt<span style="color:#f92672">.</span>timedelta(days<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>freq <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span><span style="color:#f92672">/</span><span style="color:#ae81ff">20</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>day <span style="color:#f92672">=</span> start_date
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>columns <span style="color:#f92672">=</span> [<span style="color:#e6db74">&#39;timestamp&#39;</span>, <span style="color:#e6db74">&#39;mm_precip&#39;</span>, <span style="color:#e6db74">&#39;temperature&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#39;weather_data/weather.csv&#39;</span>, mode <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;w&#39;</span>, newline<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;&#39;</span>) <span style="color:#66d9ef">as</span> csvfile:
</span></span><span style="display:flex;"><span>    writer <span style="color:#f92672">=</span> csv<span style="color:#f92672">.</span>DictWriter(csvfile, fieldnames<span style="color:#f92672">=</span>columns)
</span></span><span style="display:flex;"><span>    writer<span style="color:#f92672">.</span>writeheader()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> day <span style="color:#f92672">&lt;=</span> end_date:
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        day_string <span style="color:#f92672">=</span> day<span style="color:#f92672">.</span>strftime(<span style="color:#e6db74">&#39;%Y/%m/</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        url <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;https://api.meteo.cat/xema/v1&#39;</span> <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;/estacions/mesurades/X8/&#39;</span> <span style="color:#f92672">+</span> day_string 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        print(day_string)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        headers <span style="color:#f92672">=</span> {<span style="color:#e6db74">&#39;Accept&#39;</span>: <span style="color:#e6db74">&#39;application/json&#39;</span>, <span style="color:#e6db74">&#39;X-API-KEY&#39;</span>: key}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        data <span style="color:#f92672">=</span> requests<span style="color:#f92672">.</span>get(url, headers<span style="color:#f92672">=</span>headers)<span style="color:#f92672">.</span>json()[<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># the codi variables, 35 and 32, correspond to precipitation and temperature respectively. The json file retrieved</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># contains information on many more variables, but we are only interested in these two.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        precipitation <span style="color:#f92672">=</span> [data[<span style="color:#e6db74">&#39;variables&#39;</span>][i][<span style="color:#e6db74">&#39;lectures&#39;</span>] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(data[<span style="color:#e6db74">&#39;variables&#39;</span>])) <span style="color:#66d9ef">if</span> data[<span style="color:#e6db74">&#39;variables&#39;</span>][i][<span style="color:#e6db74">&#39;codi&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">35</span>][<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>        temperature <span style="color:#f92672">=</span> [data[<span style="color:#e6db74">&#39;variables&#39;</span>][i][<span style="color:#e6db74">&#39;lectures&#39;</span>] <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(data[<span style="color:#e6db74">&#39;variables&#39;</span>])) <span style="color:#66d9ef">if</span> data[<span style="color:#e6db74">&#39;variables&#39;</span>][i][<span style="color:#e6db74">&#39;codi&#39;</span>] <span style="color:#f92672">==</span> <span style="color:#ae81ff">32</span>][<span style="color:#ae81ff">0</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        date_variables <span style="color:#f92672">=</span> [{<span style="color:#e6db74">&#39;timestamp&#39;</span>:int(dt<span style="color:#f92672">.</span>datetime<span style="color:#f92672">.</span>strptime(d[<span style="color:#e6db74">&#39;data&#39;</span>], <span style="color:#e6db74">&#39;%Y-%m-</span><span style="color:#e6db74">%d</span><span style="color:#e6db74">T%H:%MZ&#39;</span>)<span style="color:#f92672">.</span>timestamp()), <span style="color:#e6db74">&#39;mm_precip&#39;</span>:d[<span style="color:#e6db74">&#39;valor&#39;</span>]} <span style="color:#66d9ef">for</span> d <span style="color:#f92672">in</span> precipitation]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> i <span style="color:#f92672">in</span> range(len(date_variables)):
</span></span><span style="display:flex;"><span>            date_variables[i][<span style="color:#e6db74">&#39;temperature&#39;</span>] <span style="color:#f92672">=</span> temperature[i][<span style="color:#e6db74">&#39;valor&#39;</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        writer<span style="color:#f92672">.</span>writerows(date_variables)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        day <span style="color:#f92672">+=</span> delta
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        time<span style="color:#f92672">.</span>sleep(freq)
</span></span></code></pre></div><p>Due to the capacity of the data, they are stored in <a href="https://drive.google.com/drive/folders/1ZIY2ZMhsCITuSFC1bnIDJrbZh-sS63HP?usp=drive_link">Google Drive</a>.</p>
<h3 id="b-consolidate-the-data">b. Consolidate the Data</h3>
<p>The consolidation of the Data was built in Tableau using Tableau Prep which give us more flexibility to join, filter and build the next structure according with our metadata-sample-submission.csv</p>
<h4 id="metadata-sample-submission">Metadata Sample Submission</h4>
<p><img src="/capstone-project/metadata-sample-submission.png" alt="Metadata Sample Submission"></p>
<h2 id="discover-and-visualize-the-data-to-gain-insights">Discover and visualize the data to gain insights</h2>
<p>Data consolidation, visualization and analysis with Tableau</p>
<h3 id="a-tableau-workflow">a. Tableau Workflow</h3>
<p>The first flow in Tableau Prep let you consolidate the bicing station status files of all years and create new columns like year, month, day and hour.
The flow has two sub-flows because is necessary applied the same process to bicing station 2023 files. Both flows create new files with a hyper format which is easier to manage and control the data.</p>
<p><img src="/capstone-project/first-tableau-flow.png" alt="First Tableau flow"></p>
<p>The second flow in Tableau Prep get the hyper files of bicing station status (2019-2022) to join with the last bicing station information (March, 2023) to get the extra information like longitude, latitude, name, capacity and postcode.</p>
<p><img src="/capstone-project/second-tableau-flow.png" alt="Second Tableau flow"></p>
<p>The same process is applied to the bicing station status 2023 but filtering docks_availability and bike_availability. These fields will be evaluated and predicted by the models.</p>
<p><img src="/capstone-project/third-tableau-flow.png" alt="Third Tableau flow"></p>
<p>Finally, the last flow transform the input data of the preview flow using a aggregation to the level year, month, day and hour calculating average of the rest of fields and creating four additional fields with the percent of docks availability in the four hours before.</p>
<p><img src="/capstone-project/fourth-tableau-flow.png" alt="Fourth Tableau flow"></p>
<p>Before training and testing, the data is analyzed to identify patterns, outliers and to visualize relevant features.</p>
<h3 id="b-analysis-in-tableau">b. Analysis in Tableau</h3>
<p>Visual analysis of data constructed based on the final output to identify outliers, COVID behaviors and relevant characteristics before training and testing with machine learning models</p>
<p><img src="/capstone-project/bicing-data-analysis.png" alt="Bicing Data Analysis"></p>
<p>With all the consolidate information we start to clean and processes the data to prepare our dataframes of training and testings.</p>
<h2 id="prepare-the-data-for-machine-learning-algorithms">Prepare the data for Machine Learning algorithms</h2>
<h3 id="a-importation-of-data-in-colab">a. Importation of data in Colab</h3>
<p>We load the dataframes of bicing station (validation and training), weather and testing.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>station_dataframe <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;/content/drive/MyDrive/CapstoneProject/data_bicing_joined_HX_23.csv&#39;</span>, assume_missing<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, delimiter<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;;&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>weather_dataframe <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;/content/drive/MyDrive/CapstoneProject/weather.csv&#39;</span>, assume_missing<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, delimiter<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;,&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>data_2_predict <span style="color:#f92672">=</span> dd<span style="color:#f92672">.</span>read_csv(<span style="color:#e6db74">&#39;/content/drive/MyDrive/CapstoneProject/metadata_sample_submission.csv&#39;</span>, delimiter<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;,&#39;</span>)
</span></span></code></pre></div><h3 id="b-data-cleaning-and-filtering">b. Data Cleaning and Filtering</h3>
<ul>
<li>Initial cleaning to go from the format that the Tableau merger outputs to the one desired for the model.</li>
<li>The objective of this first step is to leave the training data in the same format as the submission one.</li>
<li>Drop all rows with out of service stations and year 2020, to avoid COVID effects on our training data.</li>
<li>Select the features with the highest relevance (station_id, lat, lon, year, month, day, hour, ctx-4, ctx-3, ctx-2, ctx-1, percentage).</li>
<li>Split the data into training and validation.</li>
<li>Filter only the data with status &ldquo;IN_SERVICE&rdquo;.</li>
</ul>
<h3 id="c-processing-pipelines">c. Processing pipelines</h3>
<p>Apart from the preprocessing done using tableau to create the initial dataframe, everything else will be done using sklearn pipelines.</p>
<p>Creation of the 4 pipelines:</p>
<ul>
<li>
<p>train_preparator:</p>
<ul>
<li>to prepare the training data, not used for the submission data as we already have location data.</li>
<li>we have five transformers. The first merge the data with weather dataframe and include the creation of the datatime column.</li>
<li>the second transform add new columns of time.</li>
<li>the third and fourth transformer filter the hours to avoid overlapping and normalize datetime columnes like month, day, hour and year.</li>
</ul>
</li>
<li>
<p>submisison_preparator and val_preparator:</p>
<ul>
<li>to prepare the submission data, not used for the training data as we don&rsquo;t have location data. Not a problem since we are not fitting to any data, just transforming with data we already have</li>
<li>we keep the same transformers of the previous pipeline because we want to have the same structure with the data.</li>
</ul>
</li>
<li>
<p>scaling_pipeline:</p>
<ul>
<li>to fill and scale certain column in the data, used for both training and submission data. In this case, we are fitting to the training data, and transforming both training and submission data</li>
</ul>
</li>
</ul>
<h3 id="d-classes-and-functions">d. Classes and Functions</h3>
<p>Each pipeline is supported by a set of functions and classes to structure the data and features. The functions are included like parameters inside of the classes.</p>
<h4 id="functions">Functions</h4>
<ul>
<li>extra_time_info: add new columns of time like is_weekend, timeframe1, timeframe2, timeframe3, timeframe4, timeframe5 to group the hours</li>
<li>hour_selector: filter a range of hours to avoid overlapping with the columns with the same information of one to four hours before</li>
<li>time_norm: Time normalizer function to normalize the time columns to a 0-1 scale with periodicity. This is done by applying a sin and cos transformation to the columns</li>
<li>weather_prep:
<ul>
<li>weather dataframe preparator to leave it in the desired format to merge with the station dataframe.</li>
<li>We convert the half hourly data to hourly data by averaging temperature and summing precipitation</li>
<li>We also add a column with the datetime in order to merge the dataframes</li>
</ul>
</li>
<li>weather_merge: Merge the main dataframe with weather dataframe and split datetime column in year, month, day and hour</li>
</ul>
<h4 id="classes">Classes</h4>
<ul>
<li>hour_selector_transformer: class to encapsulate the range of hours.</li>
<li>station_loc_transformer: class to join and encapsulate the latitude and longitude.</li>
<li>station_id_dropper: the class use station id dropper function to drop the station_id column from the dataset at the end of the pipeline. The prediction will be done on the location of the stations, not on the id.</li>
<li>time_norm_transformer: class to encapsulate a time columns and normalize them using time_norm function.</li>
<li>weather_merge_transformer: class to encapsulate the weather data and merge with main dataframe.</li>
</ul>
<h3 id="e-prepare-all-data-and-load-data-that-has-been-saved">e. Prepare all data and load data that has been saved</h3>
<p>The following code load the data has been saved in the prepped_data folder, so there is no need to run this code again. We will just load it from our folder to work with the models</p>
<p>We have three datasets. The first dataset is for training purposes, the second dataset considers only a specific range of hours to avoid overlapping data with the columns, and the last dataset is our test dataset, which is loaded on Kaggle.</p>
<ul>
<li>
<p>Training Dataset</p>
<p><img src="/capstone-project/x-train.png" alt="X-Train dataset"></p>
</li>
<li>
<p>Validation Dataset (5 hr)</p>
<p><img src="/capstone-project/x-val.png" alt="X-Val dataset"></p>
</li>
<li>
<p>Validation Dataset with all hours (24 hr)</p>
<p><img src="/capstone-project/x-val24.png" alt="X-Val24 dataset"></p>
</li>
<li>
<p>Submission Dataset (Testing Dataset)</p>
<p><img src="/capstone-project/x-submission.png" alt="X-Submission dataset"></p>
</li>
</ul>
<h2 id="model-selection-and-training">Model Selection and Training</h2>
<p>For this project we will use 2 different models. The first one is an xgboost regressor, that has been chosen following other similar projects to this one and that has outperformed with less training times other similar ensemble models. Then, a neural network containing LSTM layers is used to capture the temporal features and their ordering.</p>
<h3 id="a-xgbregressor">a. XGBregressor</h3>
<p>We will first use a data subset to perform a grid search on the parameter space to find the ones that fit the best our xgboost model.</p>
<h4 id="randomizedsearchcv-and-gridsearchcv">RandomizedSearchCV and GridSearchCV</h4>
<p>We apply both techniques to find the best parameters for our model after transforming our data using pipelines. We use an XGBRegressor and a set of parameters associated with it to evaluate the optimal parameters for training and prediction.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>space <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;learning_rate&#39;</span>: [<span style="color:#ae81ff">0.1</span>, <span style="color:#ae81ff">0.01</span>, <span style="color:#ae81ff">0.001</span>],
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;max_depth&#39;</span>: [<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">7</span>],
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;subsample&#39;</span>: [<span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">0.9</span>, <span style="color:#ae81ff">1.0</span>],
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;reg_lambda&#39;</span>: [<span style="color:#ae81ff">0.1</span>, <span style="color:#ae81ff">1.0</span>, <span style="color:#ae81ff">10.0</span>],
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;reg_alpha&#39;</span>: [<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">0.1</span>, <span style="color:#ae81ff">1.0</span>],
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#39;n_estimators&#39;</span>: [<span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">200</span>]
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>xgb_model <span style="color:#f92672">=</span> XGBRegressor(objective<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;reg:squarederror&#39;</span>, random_state <span style="color:#f92672">=</span> <span style="color:#ae81ff">40</span>)
</span></span><span style="display:flex;"><span>grid_search <span style="color:#f92672">=</span> GridSearchCV(estimator<span style="color:#f92672">=</span>xgb_model, param_grid<span style="color:#f92672">=</span>space, scoring<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;neg_mean_squared_error&#39;</span>, cv<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, verbose<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>grid_search<span style="color:#f92672">.</span>fit(gs_subset, y_subset)
</span></span></code></pre></div><p>Best parameters result</p>
<p><img src="/capstone-project/grdsearch-best-parameters.png" alt="Best Parameters GridSearch"></p>
<p>Now that we have the best parameters for our subset of data we train the model. We also use the validation dataset to monitor the performance of the model during training to look for over-fitting curves</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>xgb_model <span style="color:#f92672">=</span> XGBRegressor(objective<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;reg:squarederror&#39;</span>, colsample_bytree<span style="color:#f92672">=</span><span style="color:#ae81ff">0.8</span>, gamma<span style="color:#f92672">=</span><span style="color:#ae81ff">0.1</span>, n_jobs<span style="color:#f92672">=-</span><span style="color:#ae81ff">1</span>, random_state<span style="color:#f92672">=</span><span style="color:#ae81ff">123</span>, eval_metric <span style="color:#f92672">=</span> <span style="color:#e6db74">&#39;rmse&#39;</span>, early_stopping_rounds <span style="color:#f92672">=</span> <span style="color:#ae81ff">30</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">with</span> open(<span style="color:#e6db74">&#39;/content/drive/MyDrive/CapstoneProject/xgboost models/best_params.json&#39;</span>, <span style="color:#e6db74">&#39;r&#39;</span>) <span style="color:#66d9ef">as</span> f:
</span></span><span style="display:flex;"><span>  best_params <span style="color:#f92672">=</span> json<span style="color:#f92672">.</span>load(f)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>xgb_model<span style="color:#f92672">.</span>set_params(<span style="color:#f92672">**</span>best_params)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>evalset <span style="color:#f92672">=</span> [(X_train, y_train), (X_val, y_val), (X_val24, y_val24)]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>xgb_model<span style="color:#f92672">.</span>fit(X_train, y_train, eval_set <span style="color:#f92672">=</span> evalset)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>y_pred <span style="color:#f92672">=</span> xgb_model<span style="color:#f92672">.</span>predict(X_val)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>rmse <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sqrt(mean_squared_error(y_true <span style="color:#f92672">=</span> y_val, y_pred <span style="color:#f92672">=</span> y_pred))
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#39;rmse:&#39;</span>, rmse)
</span></span></code></pre></div><p>Once we have trained the model, we are interested in knowing how the loss evolved during training, as well as what variables were the most relevant to predict the percentage of available docks</p>
<h4 id="loss-function-graphic">Loss Function Graphic</h4>
<p><img src="/capstone-project/loss-function-xgboost.png" alt="Loss Function graphic"></p>
<h4 id="most-relevant-features">Most Relevant Features</h4>
<p><img src="/capstone-project/feature-importance-xgboost.png" alt="Feature Importances Graphic"></p>
<p>The feature important plot is really interesting. From it we can conclude that:</p>
<ul>
<li>A expected, the previous hours percentage gives a lot of info about how many docks will be available in the following hours.</li>
<li>The location of the station are the next most relevant features. The usage of the service is not homogeneous across the city and this impacts to availability of docks</li>
<li>timeframe2, corresponding to peak hours in the morning has quite a bit of weight. The stations network probably has the most activity in these hours</li>
<li>the hour also affects quite a bit the final %, as expected &ndash;&gt; Since we are only training with</li>
<li>The weather does not even appear in the graph. We expected way more weight from those variables, especially rain. We guess that since Barcelona is not a very rainy city, the model does not see many registers with rain and so it end up ignoring completely the variable</li>
</ul>
<h3 id="b-lstm">b. LSTM</h3>
<p>Apart from our xgbregressor model, and since our data contains historical data, we have also tried to study the prediction problem as a time-series analysis by working with long short-term memory layers on a neural network to try and exploit the temporal ordering of the information. Since not all the variables are historical, that have built a time series with just the one that are historical context, and we have treated the rest with a fully connected network. By using this approach our intention is to capture not only the static context of the data, but also the past that leads to each station&rsquo;s state.</p>
<p>We construct a neural network by separating it into two parts, one for the time series data and one for the static data. The time series data is fed into an LSTM layer, the static data is fed into a dense layer</p>
<h4 id="neural-network-structure">Neural Network Structure</h4>
<p><img src="/capstone-project/neural-network-structure.png" alt="Neural Network"></p>
<h4 id="neural-network-results">Neural Network Results</h4>
<p><img src="/capstone-project/neural-network-results.png" alt="Neural Network Results"></p>
<p>We get recall similar results to that of the xgb model &ndash;&gt; Further improvements should come from the hand of a better preproccesing probably, working with outliers and incorrect data in a more detailed way</p>
<h2 id="heatmap-and-buffer-analysis">Heatmap and Buffer Analysis</h2>
<p>This section consists in two parts:</p>
<ul>
<li>
<p>Creation of a dinamic heat map of dock availability that can be changed based on the month and year parameter. This will allow us to understand the pattern of bicycle usage across the city.</p>
</li>
<li>
<p>Performance of a buffer analysis. Here we are going to search for areas that are near the bike lanes but do not have a nearby bike station to detect potential zones where new bike stations could be installed. The buffer has been set in 500 meters based on the size of the city and the number of stations.</p>
</li>
</ul>
<h3 id="a-libraries">a. Libraries</h3>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> folium
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> folium.plugins <span style="color:#f92672">import</span> HeatMap
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> pandas <span style="color:#66d9ef">as</span> pd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> json
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> dask.dataframe <span style="color:#66d9ef">as</span> dd
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> dash
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> dash.dependencies <span style="color:#f92672">import</span> Input, Output
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> dash <span style="color:#f92672">import</span> dcc <span style="color:#66d9ef">as</span> dcc
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> dash <span style="color:#f92672">import</span> html <span style="color:#66d9ef">as</span> html
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> base64
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> os
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> flask <span style="color:#f92672">import</span> Flask
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> io <span style="color:#f92672">import</span> BytesIO
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> jupyter_dash <span style="color:#f92672">import</span> JupyterDash
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> geopandas <span style="color:#66d9ef">as</span> gpd
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> shapely.geometry <span style="color:#f92672">import</span> LineString
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> shapely.geometry <span style="color:#f92672">import</span> Point, Polygon
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> geopy.distance
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> math
</span></span></code></pre></div><h3 id="b-heatmap">b. Heatmap</h3>
<p>The code is designed to generate and display the dinamic heatmap that represents the average availability of bike docks across the city, given a specific month and year.First, lets create a joined dataframe that will be used for the heatmap analysis</p>
<p><img src="/capstone-project/heatmap-dataframe.png" alt="Heatmap Dataframe"></p>
<p>Now we are going to calculate the average percentage of bike availability at each station using the historical data. then we will generate a heatmap based on this data, with coordinates of each station and a color intensity indicating the level of bike availability. This heatmap is overlaid onto the city map created using Folium, providing a clear visualization of bike availability in different areas of the city.</p>
<p>The resulting map is saved as an HTML file in a temporary location and then the interface powered by Dash includes dropdown menus for selecting the month and year of interest. The map updates dynamically based on these selections, providing a tool for exploring dock availability across different times.</p>
<p><img src="/capstone-project/bicing-heatmap-capture.png" alt="Heatmap"></p>
<p><img src="/capstone-project/bicing-heatmap-capture2.png" alt="Heatmap2"></p>
<p>Remarks: If we compare the different periods, we can see that in general, the downtown is the area where there is a major use of bicycle and therefore less availability.</p>
<h3 id="c-buffer-analysis">c. Buffer Analysis</h3>
<p>This produces a heatmap representing the average availability of bikes at different stations in march 2023 including the buffer analysis around bike lanes.</p>
<p>First, we define a function function to calculate the geographical distance between two points on Earth given their latitude and longitude. This function will be later used in the buffer analysis.</p>
<p>Next, we compute the average availability of bikes at each station for march 2023. This data is used to create a list of tuples where each tuple contains the latitude, longitude and availability of a bike station. The bike availability is subtracted from 1 to display lack of availability in the heatmap.</p>
<p>A base map of the city is created using Folium and the bike lanes data is loaded from a GeoJSON file and added to the map.The heatmap is added to the map using the previously computed bike station data.</p>
<p>The script then performs the buffer analysis. It iterates through each bike lane segment and checks if it&rsquo;s more than 500 meters away from any bike station. If it is, a marker is added to that point on the map. This analysis helps identify undeserved areas where additional bike stations might be needed. Then is saved as an html.</p>
<p>The output is the following:</p>
<p><a href="/capstone-project/temp_map_no_mark23.html">Buffer Analysis</a></p>
<p>Remarks: With this buffer analysis we can see that there are several areas in the city that might need a station, such as Zona franca, the port of Barcelona or near Sant Adria de Besos.</p>

        </p>
        
        <div class="post-comments">
            <div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "ilusionismo-con-github-pages" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
        </div>
        
    </div>

    <div class="prev-next">
        
    </div>
</div>

<aside class="post-toc">
    <nav id="toc">
        <nav id="TableOfContents">
  <ul>
    <li><a href="#whats-bicing-">What&rsquo;s Bicing ?</a></li>
    <li><a href="#goal">Goal</a></li>
    <li><a href="#get-the-data">Get the Data</a>
      <ul>
        <li><a href="#a-download-the-data">a. Download the Data</a></li>
        <li><a href="#b-consolidate-the-data">b. Consolidate the Data</a></li>
      </ul>
    </li>
    <li><a href="#discover-and-visualize-the-data-to-gain-insights">Discover and visualize the data to gain insights</a>
      <ul>
        <li><a href="#a-tableau-workflow">a. Tableau Workflow</a></li>
        <li><a href="#b-analysis-in-tableau">b. Analysis in Tableau</a></li>
      </ul>
    </li>
    <li><a href="#prepare-the-data-for-machine-learning-algorithms">Prepare the data for Machine Learning algorithms</a>
      <ul>
        <li><a href="#a-importation-of-data-in-colab">a. Importation of data in Colab</a></li>
        <li><a href="#b-data-cleaning-and-filtering">b. Data Cleaning and Filtering</a></li>
        <li><a href="#c-processing-pipelines">c. Processing pipelines</a></li>
        <li><a href="#d-classes-and-functions">d. Classes and Functions</a></li>
        <li><a href="#e-prepare-all-data-and-load-data-that-has-been-saved">e. Prepare all data and load data that has been saved</a></li>
      </ul>
    </li>
    <li><a href="#model-selection-and-training">Model Selection and Training</a>
      <ul>
        <li><a href="#a-xgbregressor">a. XGBregressor</a></li>
        <li><a href="#b-lstm">b. LSTM</a></li>
      </ul>
    </li>
    <li><a href="#heatmap-and-buffer-analysis">Heatmap and Buffer Analysis</a>
      <ul>
        <li><a href="#a-libraries">a. Libraries</a></li>
        <li><a href="#b-heatmap">b. Heatmap</a></li>
        <li><a href="#c-buffer-analysis">c. Buffer Analysis</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </nav>
</aside>



    

        </main><footer class="footer">
    
    
        <!-- KaTeX -->
    <p align="center">
	<a href="https://www.bicing.barcelona/">
		<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/a/a1/Bicing_logo.svg/1024px-Bicing_logo.svg.png" alt="Bicing" width="300" height="125">
	</a>
	</p>
  
    

    
    <span>&copy; 2023 The Cyclists</span>
    
    <span>
        Made with &#10084;&#65039; using <a target="_blank" href="https://github.com/526avijitgupta/gokarna">Gokarna</a>
    </span>
</footer>
</body>
</html>
